{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Cost function:\n",
    "$$J(X, \\theta) = \\sum_i ((\\theta \\cdot X) - y)^2$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradiente de la funcion de costo cuadr'atica\n",
    "def grad_quadratic(theta, f_params):\n",
    "    X = f_params['X']\n",
    "    y = f_params['y']\n",
    "\n",
    "    y_pred = theta[0]*X + theta[1] # Here theta[1] is always ones\n",
    "    err = y_pred - y\n",
    "    # Compute the partial derivatives\n",
    "    partial_0 = err\n",
    "    partial_1 = X*err\n",
    "    # Get the gradient\n",
    "    gradient = np.concatenate((partial_0, partial_1), axis=1)\n",
    "    print(gradient)\n",
    "\n",
    "    return np.sum(gradient, axis=1)"
   ]
  },
  {
   "source": [
    "## Descenso de Gradiente Simple\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD(theta, grad, gd_params, f_params):\n",
    "\n",
    "    n_iter = gd_params['n_iter']\n",
    "    alpha = gd_params['alpha']\n",
    "    # Initialize the Theta list to capture theta values\n",
    "    # at iteration t\n",
    "    Theta = []\n",
    "\n",
    "    for t in range(n_iter):\n",
    "        # Get the direction\n",
    "        p_t = - grad(theta, f_params = f_params)\n",
    "        # update the parameters\n",
    "        theta = theta + alpha * p_t\n",
    "        Theta.append(theta)\n",
    "    return np.array(Theta)"
   ]
  },
  {
   "source": [
    "## Descenso de Gradiente Estoc√°stico"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(theta, grad, gd_params, f_params):\n",
    "    (m, n) = f_params['X'].shape\n",
    "    batch_size = gd_params['batch_size']\n",
    "    n_iter = gd_params['n_iter']\n",
    "    alpha = gd_params['alpha']\n",
    "\n",
    "    Theta = []\n",
    "\n",
    "    for t in range(n_iter):\n",
    "        # Stochastic sampling\n",
    "        smp_idx = np.random.randint(\n",
    "            low=0, high=m, size=batch_size, dtype='int32')\n",
    "        # Slice the sample\n",
    "        smpX = f_params['X'][smp_idx]\n",
    "        smpy = f_params['y'][smp_idx]\n",
    "        # updte the sample\n",
    "        smpf_params = {\n",
    "            #'kappa': f_params['kappa'],\n",
    "            'X': smpX,\n",
    "            'y': smpy\n",
    "        }\n",
    "\n",
    "        # Compute the new thetas\n",
    "        p_t = - grad(theta, f_params = smpf_params)\n",
    "        theta = theta + alpha * p_t\n",
    "        \n",
    "        Theta.append(theta)\n",
    "\n",
    "        return np.array(Theta)"
   ]
  },
  {
   "source": [
    "## Descenso de Gradiente con Momento (Inercia)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MGD(theta, grad, gd_params, f_params):\n",
    "    n_iter = gd_params['n_iter']\n",
    "    alpha = gd_params['alpha']\n",
    "    eta = gd_params['eta']\n",
    "    # inizialize the p values at t=0\n",
    "    p_old = np.zeros(theta.shape)\n",
    "\n",
    "    Theta = []\n",
    "\n",
    "    for t in range(n_iter):\n",
    "        g = grad(theta, f_params = f_params)\n",
    "        p_t = "
   ]
  }
 ]
}